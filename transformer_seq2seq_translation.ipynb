{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T23:48:58.172863Z",
          "iopub.status.busy": "2023-11-26T23:48:58.172512Z",
          "iopub.status.idle": "2023-11-26T23:49:09.415004Z",
          "shell.execute_reply": "2023-11-26T23:49:09.414219Z",
          "shell.execute_reply.started": "2023-11-26T23:48:58.172831Z"
        },
        "id": "eglHoEHw1Qbb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T23:49:09.417293Z",
          "iopub.status.busy": "2023-11-26T23:49:09.416695Z",
          "iopub.status.idle": "2023-11-26T23:49:09.559130Z",
          "shell.execute_reply": "2023-11-26T23:49:09.558097Z",
          "shell.execute_reply.started": "2023-11-26T23:49:09.417263Z"
        },
        "id": "vFn1mz0B22Tn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# load training data\n",
        "\n",
        "path = \"dataset\"\n",
        "train_input = pickle.load(open(path % 'train_input', 'rb'))\n",
        "train_output = pickle.load(open(path % 'train_output', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-26T23:49:09.562203Z",
          "iopub.status.busy": "2023-11-26T23:49:09.561868Z",
          "iopub.status.idle": "2023-11-26T23:49:10.021447Z",
          "shell.execute_reply": "2023-11-26T23:49:10.020550Z",
          "shell.execute_reply.started": "2023-11-26T23:49:09.562177Z"
        },
        "id": "0sG0QuOa3Ric",
        "outputId": "6ea3a9f9-8a71-4f8f-c478-ef9dc6b4bb9f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab: {'ed', 'm', 'l', 'i', 'b', 'd', 'f', 'k', 'e', 'ef', 'a', 'eg', 'g', 'eh', 'c', 'h', 'ee', 'j'}\n",
            "Size: 18\n"
          ]
        }
      ],
      "source": [
        "# print vocabulary and its size\n",
        "\n",
        "vocab = set()\n",
        "for text in train_input:\n",
        "  vocab = vocab.union(set(text.split()))\n",
        "\n",
        "for text in train_output:\n",
        "  vocab = vocab.union(set(text.split()))\n",
        "\n",
        "print(f\"Vocab: {vocab}\\nSize: {len(vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T23:49:10.024056Z",
          "iopub.status.busy": "2023-11-26T23:49:10.023723Z",
          "iopub.status.idle": "2023-11-26T23:49:10.144444Z",
          "shell.execute_reply": "2023-11-26T23:49:10.143770Z",
          "shell.execute_reply.started": "2023-11-26T23:49:10.024029Z"
        },
        "id": "_blFTmZiDQt5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def prepend_and_append_token(texts):\n",
        "  \"\"\"\n",
        "  prepend \"[start]\" and append \"[end]\" token to each sentence\n",
        "  @texts: list of sentences\n",
        "  returns: list of sentences\n",
        "  \"\"\"\n",
        "  for i in range(len(texts)):\n",
        "    texts[i] = \"[start] \" + texts[i].strip() + \" [end]\"\n",
        "  return texts\n",
        "\n",
        "def remove_tokens(texts):\n",
        "  \"\"\"\n",
        "  remove \"[start]\" and \"[end]\" tokens\n",
        "  @texts: list of sentences\n",
        "  returns: list of sentences\n",
        "  \"\"\"\n",
        "  return [text.replace(\"[start]\", \"\").replace(\"[end]\", \"\").strip() for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EteWo0Zo-Izu"
      },
      "outputs": [],
      "source": [
        "# prepend and append tokens to training data\n",
        "\n",
        "train_input = prepend_and_append_token(train_input)\n",
        "train_output = prepend_and_append_token(train_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T23:49:10.145752Z",
          "iopub.status.busy": "2023-11-26T23:49:10.145471Z",
          "iopub.status.idle": "2023-11-26T23:49:10.269670Z",
          "shell.execute_reply": "2023-11-26T23:49:10.268894Z",
          "shell.execute_reply.started": "2023-11-26T23:49:10.145728Z"
        },
        "id": "Grt-AkwKHVAg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# split data b/w training, validation and testing\n",
        "\n",
        "input_train, input_test, output_train, output_test = train_test_split(train_input, train_output, shuffle=True, test_size=0.15)\n",
        "input_train, input_val, output_train, output_val = train_test_split(input_train, output_train, shuffle=True, test_size=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77ijVQz9FGSl"
      },
      "outputs": [],
      "source": [
        "# remove extra tokens from test data\n",
        "\n",
        "input_test = remove_tokens(input_test)\n",
        "output_test = remove_tokens(output_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T23:49:10.270981Z",
          "iopub.status.busy": "2023-11-26T23:49:10.270694Z"
        },
        "id": "nZPPudYTJSDW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# vectorize input and output vocabulary\n",
        "\n",
        "vocab_size = 200\n",
        "sequence_length = 256\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=tf.identity,\n",
        ")\n",
        "\n",
        "source_vectorization.adapt(train_input)\n",
        "target_vectorization.adapt(train_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZlTOPhtKtM-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# create batch dataset\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def format_dataset(inpL, outL):\n",
        "    inpL = source_vectorization(inpL)\n",
        "    outL = target_vectorization(outL)\n",
        "    return ({\n",
        "        \"input\": inpL,\n",
        "        \"output\": outL[:, :-1],\n",
        "    }, outL[:, 1:])\n",
        "\n",
        "def make_dataset(inp_texts, out_texts):\n",
        "    inp_texts = list(inp_texts)\n",
        "    out_texts = list(out_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((inp_texts, out_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(input_train, output_train)\n",
        "val_ds = make_dataset(input_val, output_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlkooV4GL2Ex",
        "outputId": "52398834-586b-458d-ed65-fed7ccf652fe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs['input'].shape: (64, 256)\n",
            "inputs['output'].shape: (64, 256)\n",
            "targets.shape: (64, 256)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['input'].shape: {inputs['input'].shape}\")\n",
        "    print(f\"inputs['output'].shape: {inputs['output'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RhvDbMDMi6g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "  def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.embed_dim = embed_dim\n",
        "    self.dense_dim = dense_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.attention = layers.MultiHeadAttention(\n",
        "      num_heads=num_heads, key_dim=embed_dim)\n",
        "    self.dense_proj = keras.Sequential(\n",
        "      [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "        layers.Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1 = layers.LayerNormalization()\n",
        "    self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    if mask is not None:\n",
        "      mask = mask[:, tf.newaxis, :]\n",
        "    attention_output = self.attention(\n",
        "      inputs, inputs, attention_mask=mask)\n",
        "    proj_input = self.layernorm_1(inputs + attention_output)\n",
        "    proj_output = self.dense_proj(proj_input)\n",
        "    return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\n",
        "      \"embed_dim\": self.embed_dim,\n",
        "      \"num_heads\": self.num_heads,\n",
        "      \"dense_dim\": self.dense_dim,\n",
        "    })\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-djuwFw3U_5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "  def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.token_embeddings = layers.Embedding(\n",
        "      input_dim=input_dim, output_dim=output_dim)\n",
        "    self.position_embeddings = layers.Embedding(\n",
        "      input_dim=sequence_length, output_dim=output_dim)\n",
        "    self.sequence_length = sequence_length\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "  def call(self, inputs):\n",
        "    length = tf.shape(inputs)[-1]\n",
        "    positions = tf.range(start=0, limit=length, delta=1)\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions = self.position_embeddings(positions)\n",
        "    return embedded_tokens + embedded_positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(PositionalEmbedding, self).get_config()\n",
        "    config.update({\n",
        "      \"output_dim\": self.output_dim,\n",
        "      \"sequence_length\": self.sequence_length,\n",
        "      \"input_dim\": self.input_dim,\n",
        "    })\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcvs8ID5CPZW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "  def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.embed_dim = embed_dim\n",
        "    self.dense_dim = dense_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.attention_1 = layers.MultiHeadAttention(\n",
        "      num_heads=num_heads, key_dim=embed_dim)\n",
        "    self.attention_2 = layers.MultiHeadAttention(\n",
        "      num_heads=num_heads, key_dim=embed_dim)\n",
        "    self.dense_proj = keras.Sequential(\n",
        "      [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "        layers.Dense(embed_dim),]\n",
        "    )\n",
        "    self.layernorm_1 = layers.LayerNormalization()\n",
        "    self.layernorm_2 = layers.LayerNormalization()\n",
        "    self.layernorm_3 = layers.LayerNormalization()\n",
        "    self.supports_masking = True\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\n",
        "      \"embed_dim\": self.embed_dim,\n",
        "      \"num_heads\": self.num_heads,\n",
        "      \"dense_dim\": self.dense_dim,\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def get_causal_attention_mask(self, inputs):\n",
        "    input_shape = tf.shape(inputs)\n",
        "    batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "    i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "    j = tf.range(sequence_length)\n",
        "    mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "    mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "    mult = tf.concat(\n",
        "      [tf.expand_dims(batch_size, -1),\n",
        "        tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "    return tf.tile(mask, mult)\n",
        "\n",
        "  def call(self, inputs, encoder_outputs, mask=None):\n",
        "    causal_mask = self.get_causal_attention_mask(inputs)\n",
        "    if mask is not None:\n",
        "      padding_mask = tf.cast(\n",
        "        mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "      padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "    else:\n",
        "      padding_mask = mask\n",
        "    attention_output_1 = self.attention_1(\n",
        "      query=inputs,\n",
        "      value=inputs,\n",
        "      key=inputs,\n",
        "      attention_mask=causal_mask)\n",
        "    attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "    attention_output_2 = self.attention_2(\n",
        "      query=attention_output_1,\n",
        "      value=encoder_outputs,\n",
        "      key=encoder_outputs,\n",
        "      attention_mask=padding_mask,\n",
        "    )\n",
        "    attention_output_2 = self.layernorm_2(\n",
        "      attention_output_1 + attention_output_2)\n",
        "    proj_output = self.dense_proj(attention_output_2)\n",
        "    return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcvUlbLqDA0V",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def Transformer():\n",
        "  embed_dim = 256\n",
        "  dense_dim = 1024\n",
        "  num_heads = 8\n",
        "\n",
        "  encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"input\")\n",
        "  x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "  encoder_outputs1 = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "  encoder_outputs2 = TransformerEncoder(embed_dim, dense_dim * 2, num_heads)(encoder_outputs1)\n",
        "\n",
        "  decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"output\")\n",
        "  x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "  x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs2)\n",
        "  x = TransformerDecoder(embed_dim, dense_dim * 2, num_heads)(x, encoder_outputs2)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "  transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "  return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-26T12:38:06.002158Z",
          "iopub.status.busy": "2023-11-26T12:38:06.001757Z"
        },
        "id": "Mh1Do1jnMPrS",
        "outputId": "30f2645b-dd60-4ce0-c6c8-af00fd5d83b1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1265/1265 [==============================] - 669s 519ms/step - loss: 1.1993 - accuracy: 0.5426 - val_loss: 0.6502 - val_accuracy: 0.6876\n",
            "Epoch 2/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.6756 - accuracy: 0.6821 - val_loss: 0.6351 - val_accuracy: 0.6915\n",
            "Epoch 3/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.6376 - accuracy: 0.6899 - val_loss: 0.5834 - val_accuracy: 0.6983\n",
            "Epoch 4/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.5911 - accuracy: 0.6972 - val_loss: 0.5652 - val_accuracy: 0.7055\n",
            "Epoch 5/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.5811 - accuracy: 0.7080 - val_loss: 0.5632 - val_accuracy: 0.7121\n",
            "Epoch 6/100\n",
            "1265/1265 [==============================] - 657s 519ms/step - loss: 0.5283 - accuracy: 0.7318 - val_loss: 0.4906 - val_accuracy: 0.7491\n",
            "Epoch 7/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.4786 - accuracy: 0.7541 - val_loss: 0.5016 - val_accuracy: 0.7527\n",
            "Epoch 8/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.4765 - accuracy: 0.7723 - val_loss: 0.4014 - val_accuracy: 0.8009\n",
            "Epoch 9/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.3863 - accuracy: 0.8198 - val_loss: 0.3144 - val_accuracy: 0.8579\n",
            "Epoch 10/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.2900 - accuracy: 0.8729 - val_loss: 0.2175 - val_accuracy: 0.9023\n",
            "Epoch 11/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.2186 - accuracy: 0.9034 - val_loss: 0.1604 - val_accuracy: 0.9296\n",
            "Epoch 12/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.1847 - accuracy: 0.9270 - val_loss: 0.1044 - val_accuracy: 0.9560\n",
            "Epoch 13/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0866 - accuracy: 0.9676 - val_loss: 0.0339 - val_accuracy: 0.9880\n",
            "Epoch 14/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 0.0244 - val_accuracy: 0.9914\n",
            "Epoch 15/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.0155 - val_accuracy: 0.9948\n",
            "Epoch 16/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0096 - val_accuracy: 0.9967\n",
            "Epoch 17/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.0062 - val_accuracy: 0.9979\n",
            "Epoch 18/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
            "Epoch 19/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
            "Epoch 21/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
            "Epoch 22/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
            "Epoch 23/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
            "Epoch 24/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
            "Epoch 25/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0158 - val_accuracy: 0.9955\n",
            "Epoch 26/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0025 - val_accuracy: 0.9992\n",
            "Epoch 27/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
            "Epoch 28/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 29/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
            "Epoch 30/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 31/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 32/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 33/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
            "Epoch 34/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 35/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 8.8499e-04 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 36/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Epoch 37/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
            "Epoch 38/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 39/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
            "Epoch 40/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 8.4890e-04 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 41/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 42/100\n",
            "1265/1265 [==============================] - 657s 519ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
            "Epoch 43/100\n",
            "1265/1265 [==============================] - 657s 520ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 6.9224e-04 - val_accuracy: 0.9998\n",
            "Epoch 44/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 7.0253e-04 - val_accuracy: 0.9998\n",
            "Epoch 45/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 8.9177e-04 - accuracy: 0.9998 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
            "Epoch 46/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 8.6553e-04 - val_accuracy: 0.9997\n",
            "Epoch 47/100\n",
            "1265/1265 [==============================] - 657s 519ms/step - loss: 8.3072e-04 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9992\n",
            "Epoch 48/100\n",
            "1265/1265 [==============================] - 657s 519ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 9.9941e-04 - val_accuracy: 0.9997\n",
            "Epoch 49/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 5.0660e-04 - accuracy: 0.9999 - val_loss: 7.0488e-04 - val_accuracy: 0.9998\n",
            "Epoch 50/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 5.2609e-04 - accuracy: 0.9998 - val_loss: 6.0726e-04 - val_accuracy: 0.9998\n",
            "Epoch 51/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 7.7669e-04 - accuracy: 0.9998 - val_loss: 8.5188e-04 - val_accuracy: 0.9997\n",
            "Epoch 52/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 6.5160e-04 - val_accuracy: 0.9998\n",
            "Epoch 53/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 4.8595e-04 - val_accuracy: 0.9998\n",
            "Epoch 54/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 7.9397e-04 - accuracy: 0.9998 - val_loss: 5.7638e-04 - val_accuracy: 0.9998\n",
            "Epoch 55/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 5.4602e-04 - accuracy: 0.9999 - val_loss: 4.4767e-04 - val_accuracy: 0.9999\n",
            "Epoch 56/100\n",
            "1265/1265 [==============================] - 656s 518ms/step - loss: 3.6395e-04 - accuracy: 0.9999 - val_loss: 4.6701e-04 - val_accuracy: 0.9999\n",
            "Epoch 57/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 6.6408e-04 - val_accuracy: 0.9998\n",
            "Epoch 58/100\n",
            "1265/1265 [==============================] - 656s 519ms/step - loss: 1.8560e-04 - accuracy: 1.0000 - val_loss: 6.3540e-04 - val_accuracy: 0.9998\n",
            "Epoch 59/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 8.6285e-04 - accuracy: 0.9998 - val_loss: 8.0850e-04 - val_accuracy: 0.9998\n",
            "Epoch 60/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 3.5364e-04 - accuracy: 0.9999 - val_loss: 6.1298e-04 - val_accuracy: 0.9998\n",
            "Epoch 61/100\n",
            "1265/1265 [==============================] - 655s 518ms/step - loss: 5.5197e-04 - accuracy: 0.9999 - val_loss: 6.3418e-04 - val_accuracy: 0.9998\n",
            "Epoch 62/100\n",
            " 1265/1265 [==============================] - 656s 519ms/step - loss: 5.2407e-04 - accuracy: 0.9998 - val_loss: 6.0672e-04 - val_accuracy: 0.9998\n",
            "Epoch 63/100\n",
            " 1265/1265 [==============================] - 656s 518ms/step - loss: 7.9676e-04 - accuracy: 0.9998 - val_loss: 8.8158e-04 - val_accuracy: 0.9997\n",
            "Epoch 64/100\n",
            " 1265/1265 [==============================] - 656s 519ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 7.5320e-04 - val_accuracy: 0.9998\n",
            "Epoch 65/100\n",
            " 1265/1265 [==============================] - 656s 518ms/step - loss: 3.9563e-04 - accuracy: 0.9999 - val_loss: 4.7016e-04 - val_accuracy: 0.9999\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e568dee8280>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create and train the transformer model\n",
        "\n",
        "transformer = Transformer()\n",
        "transformer.fit(train_ds,\n",
        "                epochs=100,\n",
        "                validation_data=val_ds,\n",
        "                callbacks=[\n",
        "                    keras.callbacks.ModelCheckpoint(\n",
        "                        save_best_only=True,\n",
        "                        filepath='Vaibhav_Pundir_734004197_Project2_Model.h5',\n",
        "                        monitor='val_accuracy'\n",
        "                    ),\n",
        "                    keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_accuracy',\n",
        "                        patience=10\n",
        "                    )\n",
        "                ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-23T03:18:40.365953Z",
          "iopub.status.busy": "2023-11-23T03:18:40.365072Z",
          "iopub.status.idle": "2023-11-23T03:18:40.446687Z",
          "shell.execute_reply": "2023-11-23T03:18:40.445794Z",
          "shell.execute_reply.started": "2023-11-23T03:18:40.365921Z"
        },
        "id": "mNqRsJYJnQQF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# load weights from the best model\n",
        "\n",
        "transformer.load_weights(path % 'Vaibhav_Pundir_734004197_Project2_Model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-23T02:47:52.005928Z",
          "iopub.status.busy": "2023-11-23T02:47:52.005083Z",
          "iopub.status.idle": "2023-11-23T02:47:52.016394Z",
          "shell.execute_reply": "2023-11-23T02:47:52.015384Z",
          "shell.execute_reply.started": "2023-11-23T02:47:52.005894Z"
        },
        "id": "szWSFr0vnQQF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# translate sentences from input to output language in batches\n",
        "\n",
        "out_vocab = target_vectorization.get_vocabulary()\n",
        "out_index_lookup = dict(zip(range(len(out_vocab)), out_vocab))\n",
        "max_decoded_sentence_length = 100\n",
        "\n",
        "def decode_sequences(input_sentences, transformer):\n",
        "    tokenized_input_sentences = source_vectorization(input_sentences)\n",
        "    decoded_sentences = [\"[start]\"] * len(input_sentences)\n",
        "    completed_texts = [False] * len(input_sentences)\n",
        "    batch_size = len(input_sentences)\n",
        "    count_completed = 0\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        if count_completed == batch_size:\n",
        "          break\n",
        "        tokenized_target_sentences = target_vectorization(\n",
        "            decoded_sentences)[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentences, tokenized_target_sentences])\n",
        "        sampled_token_indexes = np.argmax(predictions[:, i, :], axis=-1)\n",
        "        for j, sampled_token_index in enumerate(sampled_token_indexes):\n",
        "          if not completed_texts[j]:\n",
        "            sampled_token = out_index_lookup[sampled_token_index]\n",
        "            decoded_sentences[j] += \" \" + sampled_token\n",
        "            if sampled_token == \"[end]\":\n",
        "              completed_texts[j] = True\n",
        "              count_completed += 1\n",
        "    return decoded_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-23T03:44:42.509574Z",
          "iopub.status.busy": "2023-11-23T03:44:42.508824Z",
          "iopub.status.idle": "2023-11-23T03:44:42.514504Z",
          "shell.execute_reply": "2023-11-23T03:44:42.513605Z",
          "shell.execute_reply.started": "2023-11-23T03:44:42.509542Z"
        },
        "id": "GLdqZg9RnQQG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# helper function to call decode_sequences and return translated sentences\n",
        "\n",
        "def translate(input, transformer):\n",
        "  BATCH_SIZE = 128\n",
        "  decoded = []\n",
        "  for start in range(0, len(input), BATCH_SIZE):\n",
        "    input_texts = prepend_and_append_token(input[start: start + BATCH_SIZE])\n",
        "    decoded_texts = remove_tokens(decode_sequences(input_texts, transformer))\n",
        "    decoded.extend(decoded_texts)\n",
        "    print(f\"\\r{start+len(input_texts)}/{len(input)} done...\", end=\"\")\n",
        "\n",
        "  return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHtuk_9Z-ViG",
        "outputId": "8976baf5-94f2-42a3-ef81-3553ffd05bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16773/16800 done...\n",
            "Test Accuracy: 99.84\n"
          ]
        }
      ],
      "source": [
        "# accuracy on held out test data\n",
        "\n",
        "predicted = translate(input_test, transformer)\n",
        "match = sum(pred.strip() == true.strip() for pred, true in zip(predicted, output_test))\n",
        "test_acc = match / len(output_test) * 100\n",
        "print(f\"\\nTest Accuracy: {test_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP2dcBuKAzV0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4043016,
          "sourceId": 7029284,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30588,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
